{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import segmentation\n",
    "\n",
    "from deeplab_utils.utils import get_iou_score\n",
    "from deeplab_utils.dataset_utils import load_data, train_test_split, ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize([128, 128]),\n",
    "    ])\n",
    "\n",
    "root = '../dataset/image'\n",
    "data = load_data(root)\n",
    "_, test_data = train_test_split(data)\n",
    "\n",
    "test_dataset = ImageDataset(test_data, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'output/2024-06-17/12_41_33/best_model.pt'\n",
    "\n",
    "model = segmentation.deeplabv3_resnet101(weights='DEFAULT')\n",
    "model.classifier[4] = nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = nn.DataParallel(model, device_ids=[0, 1, 2])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)['out']\n",
    "        miou = get_iou_score(output, target)\n",
    "        \n",
    "        if miou < 0.8:\n",
    "            print(miou)\n",
    "\n",
    "            preds = output[:, 1, :, :]\n",
    "            labels = target[:, 1, :, :]\n",
    "\n",
    "            preds = torch.sigmoid(preds) > 0.5  # Apply sigmoid and threshold\n",
    "            preds = preds.long()\n",
    "            labels = labels.long()\n",
    "\n",
    "            for i in range(data.size()[0]):\n",
    "                ori_img = data[i].cpu().numpy().transpose(1, 2, 0) * 255.0\n",
    "                ori_img = ori_img.astype(np.uint8)\n",
    "\n",
    "                label_img = labels[i].cpu().numpy().squeeze() * 255.0\n",
    "                label_img = label_img.astype(np.uint8)\n",
    "                \n",
    "                out_img = preds[i].cpu().numpy().squeeze() * 255.0\n",
    "                out_img = out_img.astype(np.uint8)\n",
    "\n",
    "                # Create overlay images with transparent colors\n",
    "                label_overlay = np.zeros_like(ori_img, dtype=np.uint8)\n",
    "                label_overlay[label_img > 128] = [0, 0, 255]  # Blue color for label\n",
    "\n",
    "                out_overlay = np.zeros_like(ori_img, dtype=np.uint8)\n",
    "                out_overlay[out_img > 128] = [255, 0, 0]  # Red color for output\n",
    "\n",
    "                # Convert original image to RGB\n",
    "                ori_img_rgb = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Apply transparency to the overlays\n",
    "                alpha = 0.5\n",
    "                combined_img = cv2.addWeighted(ori_img_rgb, 1, label_overlay, alpha, 0)\n",
    "                combined_img = cv2.addWeighted(combined_img, 1, out_overlay, alpha, 0)\n",
    "\n",
    "                # Plot original and overlayed images\n",
    "                fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "                ax[0].imshow(ori_img_rgb)\n",
    "                ax[0].set_title('Original Image')\n",
    "                ax[0].axis('off')\n",
    "\n",
    "                ax[1].imshow(label_img, cmap='gray')\n",
    "                ax[1].set_title('Label Image')\n",
    "                ax[1].axis('off')\n",
    "\n",
    "                ax[2].imshow(out_img, cmap='gray')\n",
    "                ax[2].set_title('Output Image')\n",
    "                ax[2].axis('off')\n",
    "\n",
    "                ax[3].imshow(combined_img)\n",
    "                ax[3].set_title('Overlay Image')\n",
    "                ax[3].axis('off')\n",
    "\n",
    "                plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
